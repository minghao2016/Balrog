{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Balrog_0.3.2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1rAQd-UsKhliEHw_tDMGv2a_UMS4iPA3V","authorship_tag":"ABX9TyO7XCCWtzE3VSWzDCRxhJUF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6SYiIHRhZM-m","colab_type":"text"},"source":["# Google Colab Intro\n","#### This notebook downloads data and performs computations. These computations are made significantly faster with the use of a GPU, provided free by Google as part of Colab.\n","\n","#### Press the play button on the left side of each cell to run it. Alternatively, hold shift or ctrl and press enter to run cells.\n","#### Double click the top of a cell to inspect the code inside and change things. Double click the right side of the cell to hide the code.\n","#### Have fun!\n","\n","#### (bug me on github if a significantly faster c++ version would be useful to you)"]},{"cell_type":"markdown","metadata":{"id":"aEszqvakZN9C","colab_type":"text"},"source":["# Setup"]},{"cell_type":"code","metadata":{"id":"VMJQa6JAXDf_","colab_type":"code","cellView":"form","colab":{}},"source":["# @title Install dependencies\n","!pip install biopython\n","!pip install torch\n","print(\"\\nDone\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pe1PHlcjeHS8","colab_type":"code","cellView":"form","colab":{}},"source":["# @title Import python packages\n","import os\n","import sys\n","import gzip\n","import copy\n","import time\n","import pandas\n","import pickle\n","import numpy as np\n","from tqdm.auto import tqdm\n","from Bio import SeqIO\n","from scipy.special import expit\n","from scipy.special import logit\n","from multiprocessing import Pool\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.utils import weight_norm\n","\n","# # import networkx as nx\n","# from scipy.sparse import coo_matrix\n","# from scipy.sparse import csr_matrix\n","# from scipy.sparse.csgraph import bellman_ford\n","\n","print(\"Done\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"usWmfqJNhM2X","colab_type":"code","cellView":"form","colab":{}},"source":["# @title Set parameters (double click top of cell to change defaults)\n","\"\"\" Print what the program is doing.\"\"\"\n","verbose = True\n","\n","\"\"\" Maximum ORF (open reading frame) overlap length in nucleotides.\"\"\"\n","max_gene_overlap = 60\n","\n","\"\"\" Minimum ORF length in nucleotides.\"\"\"\n","min_orf_length = 60\n","\n","\"\"\" Use kmer prefilter to increase gene sensitivity. \n","May not play nice with very high GC genomes.\"\"\"\n","protein_kmer_filter = True\n","\n","\"\"\" Use mmseqs2 and a gene score cutoff to remove most false positive predictions.\"\"\"\n","mmseqs2_gene_filter = True\n","\n","\"\"\" Nucleotide to amino acid translation table. 11 for most bacteria/archaea.\n","4 for Mycoplasma/Spiroplasma.\"\"\"\n","translation_table = 11\n","# translation_table = 4\n","\n","\"\"\" Maximum number of forward connections in the directed acyclic graph used to\n","find a set of coherent genes in each genome.\n","Higher values will slow execution time and increase memory usage,\n","but may slightly increase performace.\n","Recommended range ~30-50\"\"\"\n","max_forward_connections = 50\n","\n","\"\"\" Batch size for the temporal convolutional network used to score genes.\n","Small batches and big batches slow down the model. Very big batches may crash the \n","GPU. \"\"\"\n","gene_batch_size = 200\n","TIS_batch_size = 1000\n","\n","\"\"\" All following are internal parameters. Change at your own risk.\"\"\"\n","weight_gene_prob = 0.9746869839852076 \n","weight_TIS_prob = 0.25380288790532707 \n","score_threshold = 0.47256101519707244\n","weight_ATG = 0.84249804151264 \n","weight_GTG = 0.7083689705744909\n","weight_TTG = 0.7512400826652517 \n","unidirectional_penalty_per_base = 3.895921717182765 # 3' 5' overlap\n","convergent_penalty_per_base = 4.603432608883688 # 3' 3' overlap\n","divergent_penalty_per_base = 3.3830814940689975 # 5' 5' overlap\n","k_seengene = 10\n","multimer_threshold = 2\n","model_dir = \"/home\"\n","\n","print(\"Done\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"idOvBwhe0NtP","colab_type":"code","cellView":"form","colab":{}},"source":["# @title Load pre-trained gene and translation initiation site models\n","\n","\"\"\" if you're interested in the inner workings of the \n","temporal convolutional network, see hubconf.py in the Github repo below.\"\"\"\n","\n","repo = \"salzberg-lab/Balrog\"\n","# repo = \"salzberg-lab/Balrog:develop\"\n","\n","torch.hub.set_dir(model_dir)\n","if torch.cuda.device_count() > 0:\n","    print(\"GPU detected...\")\n","    model = torch.hub.load(repo, \"geneTCN\", force_reload=True).cuda()\n","    model_tis = torch.hub.load(repo, \"tisTCN\", force_reload=False).cuda()\n","    time.sleep(0.5)\n","    print(\"\\nDone\")\n","else:\n","    print(\"No GPU detected, using CPU...\")\n","    model = torch.hub.load(repo, \"geneTCN\", force_reload=True)\n","    model_tis = torch.hub.load(repo, \"tisTCN\", force_reload=False)\n","    time.sleep(0.5)\n","    print(\"\\nDone\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wQMPFNbdk8vv","colab_type":"code","cellView":"form","colab":{}},"source":["# @title Prepare protein kmer filter\n","if protein_kmer_filter:\n","    # decompress kmer filter\n","    seengene_dir = \"/content/kmerfilter/\"\n","    !mkdir {seengene_dir}\n","    %cd {seengene_dir}\n","    !tar -xvzf /home/salzberg-lab_Balrog_master/kmer_filter/genexa_10mer_thresh2_minusARF_all.tar.gz\n","    # !tar -xvzf /home/salzberg-lab_Balrog_develop/kmer_filter/genexa_10mer_thresh2_minusARF_all.tar.gz\n","    genexa_kmer_path = os.path.join(seengene_dir, \"10mer_thresh2_minusARF_all.pkl\")\n","\n","    # load kmer filter\n","    with open(genexa_kmer_path, \"rb\") as f:\n","        aa_kmer_set = pickle.load(f)\n","\n","print(\"\\nDone\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3jzwdcGp7XN","colab_type":"code","cellView":"form","colab":{}},"source":["# @title Prepare mmseqs2\n","\n","if mmseqs2_gene_filter:\n","    ![ $(uname -m) = \"x86_64\" ] && echo \"64bit: Yes\" || echo \"64bit: No\"\n","    !grep -q sse4_1 /proc/cpuinfo && echo \"SSE4.1: Yes\" || echo \"SSE4.1: No\"\n","    !grep -q avx2 /proc/cpuinfo && echo \"AVX2: Yes\" || echo \"AVX2: No\"\n","\n","    # install\n","    !mkdir /content/mmseqs2\n","    %cd /content/mmseqs2\n","    !wget https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz\n","    !tar xvzf mmseqs-linux-avx2.tar.gz\n","\n","    # decompress fasta\n","    !mkdir /content/mmseqs2/genexa\n","    %cd /content/mmseqs2/genexa\n","    !!tar -xvzf /home/salzberg-lab_Balrog_master/protein_filter/genexa_genes.tar.gz\n","    # !!tar -xvzf /home/salzberg-lab_Balrog_develop/protein_filter/genexa_genes.tar.gz\n","    genexa_fasta_path = \"/content/mmseqs2/genexa/genexa_genes.fasta\"\n","\n","    # create DB\n","    genexa_DB_path = \"/content/mmseqs2/genexa/genexaDB\"\n","    !/content/mmseqs2/mmseqs/bin/mmseqs createdb {genexa_fasta_path} {genexa_DB_path}\n","\n","    # build mmseqs index\n","    !mkdir /content/mmseqs2/tmp\n","    !/content/mmseqs2/mmseqs/bin/mmseqs createindex {genexa_DB_path} /content/mmseqs2/tmp\n","\n","    # download swissprot DB\n","    !mkdir /content/mmseqs2/swissprot\n","    !/content/mmseqs2/mmseqs/bin/mmseqs databases UniProtKB/Swiss-Prot /content/mmseqs2/swissprot/swissprotDB /content/mmseqs2/tmp\n","    swissprot_DB_path = \"/content/mmseqs2/swissprot/swissprotDB\"\n","    \n","print(\"\\nDone\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Ea6jrhpfF4y","colab_type":"text"},"source":["# Gene Prediction (you can rerun these steps multiple times)"]},{"cell_type":"code","metadata":{"id":"uh274cXnWlva","colab_type":"code","cellView":"form","colab":{}},"source":["# @title Upload prokaryotic genomes as FASTA or gzipped FASTA (select multiple files to process multiple genomes)\n","from google.colab import files\n","genome_dict = files.upload()\n","\n","print(\"\\nDone\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NC4llyrGWIuK","colab_type":"code","cellView":"form","colab":{}},"source":["# @title Find genes\n","\n","def tokenize_aa_seq(aa_seq):\n","    \"\"\" Convert amino acid letters to integers.\"\"\"\n","    table = {\"L\": 1,\n","             \"V\": 2,\n","             \"I\": 3,\n","             \"M\": 4,\n","             \"C\": 5,\n","             \"A\": 6,\n","             \"G\": 7,\n","             \"S\": 8,\n","             \"T\": 9,\n","             \"P\": 10,\n","             \"F\": 11,\n","             \"Y\": 12,\n","             \"W\": 13,\n","             \"E\": 14,\n","             \"D\": 15,\n","             \"N\": 16,\n","             \"Q\": 17,\n","             \"K\": 18,\n","             \"R\": 19,\n","             \"H\": 20,\n","             \"*\": 0,\n","             \"X\": 0}\n","    tokenized = torch.tensor([table[aa] for aa in aa_seq])\n","    return tokenized\n","\n","\n","def get_start_codon(seq, orfcoords, strand):\n","    if strand == 1:\n","        # forward strand\n","        startcoord = orfcoords[0]\n","        return seq[startcoord-3:startcoord]\n","    else:\n","        # reverse strand\n","        startcoord = orfcoords[1]\n","        return seq[startcoord:startcoord+3].reverse_complement()\n","\n","\n","def find_ORFs(nuc_seq, minimum_length):\n","    \"\"\"find positions of all open reading frames in given reading frame\"\"\"\n","    if translation_table == 11:\n","        starts = set([\"ATG\", \"GTG\", \"TTG\"])\n","        stops = set([\"TAA\", \"TAG\", \"TGA\"])\n","    elif translation_table == 4:\n","        starts = set([\"ATG\", \"GTG\", \"TTG\"])\n","        stops = set([\"TAA\", \"TAG\"])\n","    else:\n","        print(\"Translation table \", translation_table, \" not implemented. Please open a GitHub issue if this is a problem.\")\n","        sys.exit()\n","\n","    ORF_startstop = []\n","    temp_starts = []\n","    l = len(nuc_seq)\n","    for i in range(0, l, 3): \n","        if i==0 or nuc_seq[i:i+3] in starts:\n","            temp_starts.append(i)\n","            continue\n","        if ((nuc_seq[i:i+3] in stops) or (i+3==l)) and len(temp_starts) != 0:\n","            for start in temp_starts:\n","                if (i-start >= minimum_length):\n","                    ORF_startstop.append((start, i))\n","            temp_starts = []\n","    return ORF_startstop\n","\n","def get_ORF_info(seq_list):\n","    ORF_seq = []\n","    ORF_coord = []\n","    ORF_nucseq = []\n","    for i, seq in enumerate(seq_list[:]):\n","        # frame 0: starts at 0\n","        # frame 1: starts at 1\n","        # frame 2: starts at 2\n","        # frame r0: ends at 0, MAY NOT START AT THE LAST COORD DUE TO MULTIPLE OF 3 DIFFERENCES\n","        # frame r1: ends at 1\n","        # frame r2: ends at 2\n","\n","        seqstr = str(seq)\n","        seq_c = seq.complement()\n","        seqstr_c = str(seq_c)\n","        l = len(seqstr)\n","        frame_0_end = (l-0)-(l-0)%3+0\n","        frame_1_end = (l-1)-(l-1)%3+1\n","        frame_2_end = (l-2)-(l-2)%3+2\n","\n","        frame_0 = find_ORFs(seqstr[0:frame_0_end], min_orf_length)\n","        frame_1 = find_ORFs(seqstr[1:frame_1_end], min_orf_length)\n","        frame_2 = find_ORFs(seqstr[2:frame_2_end], min_orf_length)\n","\n","        frame_r0 = find_ORFs(seqstr_c[0:frame_0_end][::-1], min_orf_length)\n","        frame_r1 = find_ORFs(seqstr_c[1:frame_1_end][::-1], min_orf_length)\n","        frame_r2 = find_ORFs(seqstr_c[2:frame_2_end][::-1], min_orf_length)\n","\n","        # standardize coords\n","        ORF_0f_standard_nuccoord = [(x[0]+3, x[1]) for x in frame_0]\n","        ORF_1f_standard_nuccoord = [(x[0]+4, x[1]+1) for x in frame_1]\n","        ORF_2f_standard_nuccoord = [(x[0]+5, x[1]+2) for x in frame_2]\n","\n","        ORF_0r_standard_nuccoord = [(frame_0_end-x[1], frame_0_end-x[0]-3) for x in frame_r0]\n","        ORF_1r_standard_nuccoord = [(frame_1_end-x[1], frame_1_end-x[0]-3) for x in frame_r1]\n","        ORF_2r_standard_nuccoord = [(frame_2_end-x[1], frame_2_end-x[0]-3) for x in frame_r2]\n","\n","        # translate once per frame, then slice\n","        aa_0 = str(seq[0:frame_0_end].translate(table=translation_table, to_stop=False))\n","        aa_1 = str(seq[1:frame_1_end].translate(table=translation_table, to_stop=False))\n","        aa_2 = str(seq[2:frame_2_end].translate(table=translation_table, to_stop=False))\n","        aa_r0 = str(seq_c[0:frame_0_end][::-1].translate(table=translation_table, to_stop=False))\n","        aa_r1 = str(seq_c[1:frame_1_end][::-1].translate(table=translation_table, to_stop=False))\n","        aa_r2 = str(seq_c[2:frame_2_end][::-1].translate(table=translation_table, to_stop=False))\n","\n","        ORF_0f_aa = [aa_0[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_0] # reversed because model is trained with first amino acid directly upstream of stop codon\n","        ORF_1f_aa = [aa_1[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_1] \n","        ORF_2f_aa = [aa_2[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_2]\n","        ORF_0r_aa = [aa_r0[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_r0]\n","        ORF_1r_aa = [aa_r1[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_r1]\n","        ORF_2r_aa = [aa_r2[slice(*tuple(int(idx/3) for idx in x))][::-1] for x in frame_r2]\n","\n","        ORF_seq.append([ORF_0f_aa, ORF_1f_aa, ORF_2f_aa, \n","                        ORF_0r_aa, ORF_1r_aa, ORF_2r_aa])\n","        ORF_coord.append([ORF_0f_standard_nuccoord, ORF_1f_standard_nuccoord, ORF_2f_standard_nuccoord, \n","                          ORF_0r_standard_nuccoord, ORF_1r_standard_nuccoord, ORF_2r_standard_nuccoord])\n","        \n","        ORF_nucseq.append([str(seq[0:frame_0_end]), # all 5' to 3'\n","                           str(seq[1:frame_1_end]),\n","                           str(seq[2:frame_2_end]),\n","                           str(seq_c[0:frame_0_end][::-1]),\n","                           str(seq_c[1:frame_1_end][::-1]),\n","                           str(seq_c[2:frame_2_end][::-1])])\n","    return ORF_seq, ORF_nucseq, ORF_coord\n","\n","\n","def analyze_overlap(coords0, coords1, strand0, strand1,\n","                    unidirectional_penalty_per_base,\n","                    convergent_penalty_per_base,\n","                    divergent_penalty_per_base):\n","    overlap = coords0[1] - coords1[0] # TODO account for fully overlapped gene\n","\n","    if overlap <= 0:\n","        compatible, penalty = True, 0\n","        return compatible, penalty\n","    \n","    if overlap > max_gene_overlap:\n","        compatible, penalty = False, 0\n","        return compatible, penalty\n","\n","    # get prime locations\n","    if strand0 == 1:\n","        threeprime0 = coords0[1]\n","        fiveprime0 = coords0[0]\n","    else:\n","        threeprime0 = coords0[0]\n","        fiveprime0 = coords0[1]\n","    if strand1 == 1:\n","        threeprime1 = coords1[1]\n","        fiveprime1 = coords1[0]\n","    else:\n","        threeprime1 = coords1[0]\n","        fiveprime1 = coords1[1]\n","    \n","    # exclude ORFs in same frame sharing same stop codon\n","    if strand0 == strand1 and threeprime0 == threeprime1:\n","        compatible, penalty = False, 0\n","        return compatible, penalty\n","\n","    # unidirectional overlap\n","    if (threeprime0 < fiveprime0) == (threeprime1 < fiveprime1):\n","        compatible, penalty = True, overlap * unidirectional_penalty_per_base\n","        return compatible, penalty\n","\n","    # convergent overlap\n","    if (fiveprime0 < threeprime1 <= threeprime0) or (fiveprime1 < threeprime0 <= threeprime1):\n","        compatible, penalty = True, overlap * convergent_penalty_per_base\n","        return compatible, penalty\n","    \n","    # divergent overlap\n","    if (threeprime0 < fiveprime1 <= fiveprime0) or (threeprime1 < fiveprime0 <= fiveprime1):\n","        compatible, penalty = True, overlap * divergent_penalty_per_base\n","        return compatible, penalty\n","\n","    return True, 0 # edge case of exactly 1 ORF\n","\n","def predict(X):\n","    model.eval()\n","    with torch.no_grad():\n","        if torch.cuda.device_count() > 0:\n","            X_enc = F.one_hot(X, 21).permute(0,2,1).float().cuda()\n","            probs = expit(model(X_enc).cpu())\n","            del X_enc\n","            torch.cuda.empty_cache()\n","        else:\n","            X_enc = F.one_hot(X, 21).permute(0,2,1).float()\n","            probs = expit(model(X_enc).cpu())\n","\n","    return probs\n","\n","def predict_tis(X):\n","    model_tis.eval()\n","    with torch.no_grad():\n","        if torch.cuda.device_count() > 0:\n","            X_enc = F.one_hot(X, 4).permute(0,2,1).float().cuda()\n","        else:\n","            X_enc = F.one_hot(X, 4).permute(0,2,1).float()\n","        probs = expit(model_tis(X_enc).cpu())\n","    return probs\n","\n","nuc_encode = {\"A\":0,\n","              \"T\":1,\n","              \"G\":2,\n","              \"C\":3,\n","              \"N\":0,\n","              \"M\":0,\n","              \"R\":0,\n","              \"Y\":0,\n","              \"W\":0,\n","              \"K\":0}\n","              \n","start_enc = {\"ATG\":0,\n","             \"GTG\":1,\n","             \"TTG\":2}\n","\n","def tensor_to_seq(tensor):\n","    table = {0: \"X\",\n","             1: \"L\",\n","             2: \"V\",\n","             3: \"I\",\n","             4: \"M\",\n","             5: \"C\",\n","             6: \"A\",\n","             7: \"G\",\n","             8: \"S\",\n","             9: \"T\",\n","             10: \"P\",\n","             11: \"F\",\n","             12: \"Y\",\n","             13: \"W\",\n","             14: \"E\",\n","             15: \"D\",\n","             16: \"N\",\n","             17: \"Q\",\n","             18: \"K\",\n","             19: \"R\",\n","             20: \"H\"}\n","    return \"\".join([table[x] for x in tensor])\n","\n","def kmerfilter(seq):\n","    kmerset = kmerize(seq, k_seengene)\n","    s = [x in aa_kmer_set for x in kmerset]\n","    seen = np.sum(s) >= multimer_threshold\n","    return seen\n","\n","def kmerize(seq, k):\n","    kmerset = set()\n","    for i in range(len(seq) - k + 1):\n","        kmer = tuple(seq[i: i + k].tolist())\n","        kmerset.add(kmer)\n","    return kmerset\n","\n","# find genes for each uploaded genome\n","GCF_list = []\n","contig_name_list = []\n","contig_length_list = []\n","contig_seq_list = []\n","contig_gene_coord_list = []\n","contig_gene_strand_list = []\n","\n","for genome_name in genome_dict.keys():\n","    if verbose:\n","        print(\"Reading fasta file\", str(genome_name) + \"...\\n\")\n","\n","    # read genome sequence\n","    seq_list = []\n","    contig_name_sublist = []\n","    contig_length_sublist = []\n","    if os.path.splitext(genome_name)[1].lower() == \".gz\":\n","        with gzip.open(genome_name, \"rt\") as f:\n","            for record in SeqIO.parse(f, \"fasta\"):\n","                seq_list.append(record.seq)\n","                contig_name_sublist.append(record.id)\n","                contig_length_sublist.append(len(record.seq))\n","    else:\n","        with open(genome_name, \"rt\") as f:\n","            for record in SeqIO.parse(f, \"fasta\"):\n","                seq_list.append(record.seq)\n","                contig_name_sublist.append(record.id)\n","                contig_length_sublist.append(len(record.seq))\n","    contig_name_list.append(contig_name_sublist)\n","    contig_length_list.append(contig_length_sublist)\n","    contig_seq_list.append(seq_list)\n","\n","    # get sequences and coordinates of ORFs\n","    if verbose:\n","        print(\"Finding and translating open reading frames...\\n\")\n","\n","    ORF_seq_list, ORF_nucseq_list, ORF_coord_list = get_ORF_info(seq_list)\n","\n","    # combine ORFs to submit to GPU in batches\n","    ORF_seq_combine = []\n","    for i, contig in enumerate(ORF_seq_list):\n","        for j, frame in enumerate(contig):\n","            for k, coord in enumerate(frame):\n","                ORF_seq_combine.append(coord)\n","\n","    # encode amino acids as integers\n","    if verbose:\n","        print(\"Encoding amino acids...\\n\")\n","    ORF_seq_enc = [tokenize_aa_seq(x) for x in ORF_seq_combine]\n","\n","    # seengene check\n","    if protein_kmer_filter:\n","        if verbose:\n","            print(\"Applying protein kmer filter...\\n\")\n","        seengene = []\n","        for s in ORF_seq_enc:\n","            kmerset = kmerize(s, k_seengene)\n","            s = [x in aa_kmer_set for x in kmerset]\n","            seen = np.sum(s) >= multimer_threshold\n","\n","            seengene.append(seen)\n","\n","    # score\n","    if verbose:\n","        print(\"Scoring ORFs with temporal convolutional network...\\n\")\n","\n","    # sort by length to minimize impact of batch padding \n","    ORF_lengths = np.asarray([len(x) for x in ORF_seq_enc])\n","    length_idx = np.argsort(ORF_lengths)\n","    ORF_seq_sorted = [ORF_seq_enc[i] for i in length_idx]\n","\n","    # pad to allow creation of batch matrix\n","    prob_list = []\n","    for i in tqdm(range(0, len(ORF_seq_sorted), gene_batch_size), unit=\" batch\"):\n","        batch = ORF_seq_sorted[i:i+gene_batch_size]\n","        seq_lengths = torch.LongTensor(list(map(len, batch)))\n","        seq_tensor = torch.zeros((len(batch), seq_lengths.max())).long()\n","\n","        for idx, (seq, seqlen) in enumerate(zip(batch, seq_lengths)):\n","            seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n","\n","        pred_all = predict(seq_tensor)\n","\n","        pred = []\n","        for j, length in enumerate(seq_lengths):\n","            subseq = pred_all[j, 0, 0:int(length)]\n","            predprob = float(expit(torch.mean(logit(subseq))))\n","            pred.append(predprob)\n","        \n","        prob_list.extend(pred)\n","    prob_arr = np.asarray(prob_list, dtype=float)\n","\n","    # unsort\n","    unsort_idx = np.argsort(length_idx)\n","    ORF_prob = prob_arr[unsort_idx]\n","\n","    # recombine ORFs\n","    idx = 0\n","    ORF_gene_score = copy.deepcopy(ORF_coord_list) # fill coord matrix with scores\n","    for i, contig in enumerate(ORF_gene_score):\n","        for j, frame in enumerate(contig):\n","            for k, coord in enumerate(frame):\n","                ORF_gene_score[i][j][k] = float(ORF_prob[idx])\n","                idx += 1\n","\n","    # create strand information\n","    ORF_strand_flat = []\n","    for i, seq in enumerate(ORF_seq_list):\n","        if not any(seq):\n","            ORF_strand_flat.append([])\n","            continue\n","        n_forward = len(seq[0]) + len(seq[1]) + len(seq[2])\n","        n_reverse = len(seq[3]) + len(seq[4]) + len(seq[5])\n","        ORF_allframe_strand = [1]*n_forward + [-1]*n_reverse\n","        ORF_strand_flat.append(ORF_allframe_strand)\n","\n","    # flatten coords within contigs\n","    ORF_coord_flat = [[item for sublist in x for item in sublist] for x in ORF_coord_list]\n","\n","    # get ORF lengths\n","    ORF_length_flat = [[coords[1]-coords[0] for coords in x] for x in ORF_coord_flat]\n","    \n","    if verbose:\n","        print(\"Scoring translation initiation sites...\\n\")\n","\n","    # extract nucleotide sequence surrounding potential start codons\n","    ORF_TIS_seq = copy.deepcopy(ORF_coord_list)\n","    ORF_start_codon = copy.deepcopy(ORF_coord_list)\n","\n","    for i, contig in enumerate(ORF_TIS_seq):\n","        n = 0 # count to index into flat structure # TODO make sure this works as expected\n","\n","        nucseq = ORF_nucseq_list[i][0] # easier to use coords relative to single nucseq\n","        nucseq_c = ORF_nucseq_list[i][3][::-1]\n","        contig_nuclength = len(nucseq)\n","\n","\n","        for j, frame in enumerate(contig):\n","            for k, temp in enumerate(frame):\n","                if any(temp):\n","                    coords = ORF_coord_list[i][j][k]\n","                    strand = ORF_strand_flat[i][n]\n","                    n += 1\n","                    if strand == 1:\n","                        fiveprime = coords[0]\n","                        if fiveprime >= 16 + 3: # NOTE 16 HARD CODED HERE\n","                            downstream = nucseq[fiveprime: fiveprime + 16]\n","                            upstream = nucseq[fiveprime - 16 - 3: fiveprime - 3]\n","                            start_codon = start_enc[nucseq[fiveprime-3: fiveprime]]\n","                            TIS_seq = torch.tensor([nuc_encode[c] for c in (upstream + downstream)[::-1]], dtype=int) # model scores 3' to 5' direction\n","                        else:\n","                            TIS_seq = -1 # deal with gene fragments later\n","                            start_codon = 2\n","\n","                        ORF_TIS_seq[i][j][k] = TIS_seq\n","                        ORF_start_codon[i][j][k] = start_codon\n","                        \n","                    else: # reverse strand\n","                        fiveprime = coords[1]\n","                        if contig_nuclength - fiveprime + 3 >= 16 + 3: # NOTE 16 HARD CODED HERE\n","                            downstream = nucseq_c[fiveprime - 16: fiveprime][::-1]\n","                            upstream = nucseq_c[fiveprime + 3: fiveprime + 3 + 16][::-1]\n","                            start_codon = start_enc[nucseq_c[fiveprime: fiveprime + 3][::-1]]\n","                            TIS_seq = torch.tensor([nuc_encode[c] for c in (upstream + downstream)[::-1]], dtype=int) # model scores 3' to 5' direction\n","                        else:\n","                            TIS_seq = -1 # deal with gene fragments later\n","                            start_codon = 2\n","                            \n","                        ORF_TIS_seq[i][j][k] = TIS_seq\n","                        ORF_start_codon[i][j][k] = start_codon\n","\n","    # flatten TIS for batching\n","    ORF_TIS_prob = copy.deepcopy(ORF_TIS_seq)\n","\n","    ORF_TIS_seq_flat = []\n","    ORF_TIS_seq_idx = []\n","    for i, contig in enumerate(ORF_TIS_seq):\n","        for j, frame in enumerate(contig):\n","            for k, seq in enumerate(frame):\n","                if type(seq) == int: # fragment\n","                    ORF_TIS_prob[i][j][k] = 0.5 # HOW BEST TO DEAL WITH FRAGMENT TIS?\n","                elif len(seq) != 32:\n","                    ORF_TIS_prob[i][j][k] = 0.5 \n","                else:\n","                    ORF_TIS_seq_flat.append(seq)\n","                    ORF_TIS_seq_idx.append((i, j, k))\n","\n","    # batch score TIS\n","    TIS_prob_list = []\n","    for i in tqdm(range(0, len(ORF_TIS_seq_flat), TIS_batch_size), unit=\" batch\"):\n","        batch = ORF_TIS_seq_flat[i:i+TIS_batch_size]\n","        TIS_stacked = torch.stack(batch)\n","        pred = predict_tis(TIS_stacked)\n","\n","        TIS_prob_list.extend(pred)\n","    y_pred_TIS = np.asarray(TIS_prob_list, dtype=float)\n","\n","    # reindex batched scores\n","    for i, prob in enumerate(y_pred_TIS):\n","        idx = ORF_TIS_seq_idx[i]\n","        ORF_TIS_prob[idx[0]][idx[1]][idx[2]] = float(prob)\n","\n","    # combine all info into single score for each ORF\n","    if protein_kmer_filter:\n","        ORF_score_flat = []\n","        for i, contig in enumerate(ORF_gene_score):\n","            if not any(contig):\n","                ORF_score_flat.append([])\n","                continue\n","            temp = []\n","            seengene_idx = 0\n","            for j, frame in enumerate(contig):\n","                for k, geneprob in enumerate(frame):\n","                    length = ORF_coord_list[i][j][k][1] - ORF_coord_list[i][j][k][0] + 1 \n","                    TIS_prob = ORF_TIS_prob[i][j][k]\n","                    start_codon = ORF_start_codon[i][j][k]\n","                    ATG = start_codon == 0\n","                    GTG = start_codon == 1\n","                    TTG = start_codon == 2\n","\n","                    combprob =   geneprob * weight_gene_prob \\\n","                            + TIS_prob * weight_TIS_prob \\\n","                            + ATG * weight_ATG \\\n","                            + GTG * weight_TTG \\\n","                            + TTG * weight_GTG\n","                    maxprob = weight_gene_prob + weight_TIS_prob + max(weight_ATG, weight_TTG, weight_GTG)\n","                    probthresh = score_threshold * maxprob\n","                    score = (combprob - probthresh) * length  + 1e6*seengene[seengene_idx]\n","                    seengene_idx += 1\n","\n","                    temp.append(score)\n","            ORF_score_flat.append(temp)\n","\n","    else:\n","        ORF_score_flat = []\n","        for i, contig in enumerate(ORF_gene_score):\n","            if not any(contig):\n","                ORF_score_flat.append([])\n","                continue\n","            temp = []\n","            for j, frame in enumerate(contig):\n","                for k, geneprob in enumerate(frame):\n","                    length = ORF_coord_list[i][j][k][1] - ORF_coord_list[i][j][k][0] + 1 \n","                    TIS_prob = ORF_TIS_prob[i][j][k]\n","                    start_codon = ORF_start_codon[i][j][k]\n","                    ATG = start_codon == 0\n","                    GTG = start_codon == 1\n","                    TTG = start_codon == 2\n","\n","                    combprob =   geneprob * weight_gene_prob \\\n","                            + TIS_prob * weight_TIS_prob \\\n","                            + ATG * weight_ATG \\\n","                            + GTG * weight_TTG \\\n","                            + TTG * weight_GTG\n","                    maxprob = weight_gene_prob + weight_TIS_prob + max(weight_ATG, weight_TTG, weight_GTG)\n","                    probthresh = score_threshold * maxprob\n","                    score = (combprob - probthresh) * length\n","\n","                    temp.append(score)\n","            ORF_score_flat.append(temp)\n","\n","    # DAGs to maximize geneiness on each contig\n","    contig_gene_coord = []\n","    contig_gene_strand = []\n","\n","    for i, coords in enumerate(ORF_coord_flat):\n","        if verbose:\n","            print(\"Creating graph of contig \" + str(i) + \"...\\n\")\n","\n","        # sort coords, lengths, strands, and scores\n","        startpos = np.array([x[0] for x in coords])\n","        sortidx = list(np.argsort(startpos))\n","\n","        coords_sorted = [coords[j] for j in sortidx]\n","\n","        lengths = ORF_length_flat[i]\n","        lengths_sorted = [lengths[j] for j in sortidx]\n","\n","        scores = ORF_score_flat[i]\n","        scores_sorted = [scores[j] for j in sortidx]\n","\n","        strands = ORF_strand_flat[i]\n","        strands_sorted = [strands[j] for j in sortidx]\n","\n","        # create DAG\n","        # keep track of graph path and score\n","        predecessor = np.zeros(len(scores_sorted), dtype=np.int64)\n","        max_path_score = np.zeros(len(scores_sorted), dtype=np.int64)\n","\n","        # add null starting node\n","        n_connections = 0\n","        idx_offset = 1\n","        while n_connections < max_forward_connections:\n","            k = idx_offset\n","            idx_offset += 1\n","            if k > len(scores_sorted)-1: # dont try to add edge past last ORF\n","                n_connections += 1\n","                continue\n","            edge_weight = scores_sorted[k-1]\n","\n","            # initial scores from null node\n","            max_path_score[k] = edge_weight\n","            predecessor[k] = 0\n","            \n","            n_connections += 1\n","\n","        # add edges between compatible ORFs\n","        for j in tqdm(range(1, len(scores_sorted)-1), unit=\" ORF\"):\n","            n_connections = 0\n","            idx_offset = 1\n","\n","            while n_connections < max_forward_connections:\n","                k = j + idx_offset\n","                idx_offset += 1\n","\n","                if k > len(scores_sorted)-1: # dont try to add edge past end of contigs\n","                    n_connections += 1\n","                    continue \n","\n","                coords0 = coords_sorted[j-1]\n","                coords1 = coords_sorted[k-1]\n","\n","                strand0 = strands_sorted[j-1]\n","                strand1 = strands_sorted[k-1]\n","\n","                compat, penalty = analyze_overlap(coords0, coords1, \n","                                                  strand0, strand1,\n","                                                  unidirectional_penalty_per_base,\n","                                                  convergent_penalty_per_base,\n","                                                  divergent_penalty_per_base)\n","\n","                if compat:\n","                    score = scores_sorted[k-1] - penalty\n","\n","                    path_score = max_path_score[j] + score\n","                    if path_score > max_path_score[k]:\n","                        max_path_score[k] = path_score\n","                        predecessor[k] = j\n","\n","                    n_connections += 1\n","\n","\n","        # solve for geneiest path through contig\n","        if verbose:\n","            print(\"Maximizing geneiness...\")\n","\n","        pred_idx = np.argmax(max_path_score)\n","        pred_path = []\n","        while pred_idx > 0:\n","            pred_path.append(pred_idx)\n","            pred_idx = predecessor[pred_idx]\n","\n","        # max_ORF_PATH = [x-1 for x in max_ORF_PATH_withnull[1:]]\n","        max_ORF_PATH = [x-1 for x in pred_path[:]] # 0 isnt added\n","\n","        gene_predict_coords = [coords_sorted[j] for j in max_ORF_PATH]\n","        gene_predict_strand = [strands_sorted[j] for j in max_ORF_PATH]\n","\n","        # mmseqs filter\n","        if mmseqs2_gene_filter:\n","            if verbose:\n","                print(\"\\nFiltering predictions with mmseqs2...\")\n","\n","            # get amino acid sequence from coherent ORFs\n","            # 3' TO 5'\n","            aa_sorted = [ORF_seq_enc[j] for j in sortidx]\n","            aa_tensor = [aa_sorted[j] for j in max_ORF_PATH]\n","            aa_seq = [tensor_to_seq([int(y) for y in x]) for x in aa_tensor]\n","\n","            # make temp dir to store mmseqs stuff\n","            finding_empty_dir = True\n","            dir_idx = 0\n","            while finding_empty_dir:\n","                dirpath = os.path.join(\"/content/mmseqs2/tmp\", str(dir_idx))\n","                if os.path.isdir(dirpath):\n","                    dir_idx += 1\n","                    continue\n","                else:\n","                    !mkdir {dirpath}\n","                    finding_empty_dir = False\n","            \n","            # mmseqs create query DB     3' to 5'\n","            query_fasta_path_35 = os.path.join(dirpath, \"candidate_genes_35.fasta\")\n","            with open(query_fasta_path_35, \"w\") as f:\n","                for i, s in enumerate(aa_seq):\n","                    f.writelines(\">\" + str(i) + \"\\n\")\n","                    f.writelines(str(s) + \"\\n\")\n","\n","            # mmseqs create query DB     5' to 3'\n","            query_fasta_path_53 = os.path.join(dirpath, \"candidate_genes_53.fasta\")\n","            with open(query_fasta_path_53, \"w\") as f:\n","                for i, s in enumerate(aa_seq):\n","                    f.writelines(\">\" + str(i) + \"\\n\")\n","                    f.writelines(str(s)[::-1] + \"\\n\")\n","\n","            query_DB_path_35 = os.path.join(dirpath, \"candidateDB_35\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs createdb {query_fasta_path_35} {query_DB_path_35}\n","            \n","            query_DB_path_53 = os.path.join(dirpath, \"candidateDB_53\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs createdb {query_fasta_path_53} {query_DB_path_53}\n","            \n","            # mmseqs search\n","            results_DB_path_35 = os.path.join(dirpath, \"resultsDB_35\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs search -s 7.0 {query_DB_path_35} {genexa_DB_path} {results_DB_path_35} {dirpath}\n","\n","            # convert to readable format\n","            m8_path_genexa = os.path.join(dirpath, \"resultDB_genexa.m8\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs convertalis {query_DB_path_35} {genexa_DB_path} {results_DB_path_35} {m8_path_genexa} --format-output \"query,target,evalue,raw\"\n","\n","            # load search results\n","            mmseqs_results_genexa = pandas.read_table(m8_path_genexa, header=None, names=[\"query\", \"target\", \"evalue\", \"raw\"]).to_numpy()\n","\n","            # get hits\n","            hit_idx_genexa = np.unique(mmseqs_results_genexa[:, 0]).astype(int)\n","\n","            # mmseqs search\n","            results_DB_path_53 = os.path.join(dirpath, \"resultsDB_53\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs search -s 7.0 {query_DB_path_53} {swissprot_DB_path} {results_DB_path_53} {dirpath}\n","\n","            # convert to readable format\n","            m8_path_secondary = os.path.join(dirpath, \"resultDB_secondary.m8\")\n","            !/content/mmseqs2/mmseqs/bin/mmseqs convertalis {query_DB_path_53} {swissprot_DB_path} {results_DB_path_53} {m8_path_secondary} --format-output \"query,target,evalue,raw\"\n","\n","            # load search results\n","            mmseqs_results_secondary = pandas.read_table(m8_path_secondary, header=None, names=[\"query\", \"target\", \"evalue\", \"raw\"]).to_numpy()\n","\n","            # get hits\n","            hit_idx_secondary = np.unique(mmseqs_results_secondary[:, 0]).astype(int)\n","\n","            # filter gene predictions, keep if mmseqs hit or high enough gene score\n","            cutoff = 200\n","\n","            cutoffpath = [x for i, x in enumerate(max_ORF_PATH) if (scores_sorted[x] > cutoff or (i in hit_idx_genexa or i in hit_idx_secondary))]\n","            gene_predict_coords = [coords_sorted[j] for j in cutoffpath]\n","            gene_predict_strand = [strands_sorted[j] for j in cutoffpath]\n","\n","            graph_score_cutoff = [scores_sorted[j] for j in cutoffpath]\n","            contig_gene_coord.append(gene_predict_coords)\n","            contig_gene_strand.append(gene_predict_strand)\n","\n","            n_genes = len(gene_predict_coords)\n","            if verbose:\n","                print(\"found\", n_genes, \"genes\\n\\n\")\n","\n","        else:\n","            cutoff = 100\n","            cutoffpath = [x for x in max_ORF_PATH if scores_sorted[x] > cutoff]\n","            gene_predict_coords = [coords_sorted[j] for j in cutoffpath]\n","            gene_predict_strand = [strands_sorted[j] for j in cutoffpath]\n","\n","            graph_score_cutoff = [scores_sorted[j] for j in cutoffpath]\n","            contig_gene_coord.append(gene_predict_coords)\n","            contig_gene_strand.append(gene_predict_strand)\n","\n","            n_genes = len(gene_predict_coords)\n","            if verbose:\n","                print(\"found\", n_genes, \"genes\\n\\n\")\n","    contig_gene_coord_list.append(contig_gene_coord)\n","    contig_gene_strand_list.append(contig_gene_strand)\n","\n","print(\"Done\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M3_sRPUzDfkX","colab_type":"code","cellView":"form","colab":{}},"source":["# @title Download genome annotation (you may need to rerun this cell and/or allow multiple downloads in browser)\n","# TODO support different output formats\n","\n","def write_GFF(start, end, contig, strand, contig_name_all, contig_length_all, contig_seq_all, GFF_path_out):\n","    # writes to same format as Prokka GFF\n","    bases_per_line = 60\n","    with open(GFF_path_out, \"wt\") as f:\n","        # header\n","        f.writelines([\"##gff-version 3\\n\"])\n","\n","        # contig names and lengths\n","        datalines = [\" \".join([\"##sequence-region\", \n","                               str(contig_name_all[i]), \n","                               \"1\", \n","                               str(contig_length_all[i]), \n","                               \"\\n\"]) for i in range(len(contig_name_all))]\n","        f.writelines(datalines)\n","\n","        # CDS features\n","        datalines = [\"\\t\".join([contig[i],\n","                                \"Balrog\",\n","                                \"CDS\",\n","                                str(int(start[i]) + 1),\n","                                end[i],\n","                                \".\", # TODO: replace . with actual gene score\n","                                strand[i],\n","                                \"0\",\n","                                \"inference=ab initio prediction:Balrog;product=hypothetical protein\"\n","                                \"\\n\"]) for i in range(len(start))]\n","        f.writelines(datalines)\n","\n","        # # contig sequences\n","        # f.writelines([\"##FASTA\", \"\\n\"])\n","        # for i, name in enumerate(contig_name_all):\n","        #     f.writelines([\">\", str(name), \"\\n\"])\n","        #     bases_per_line = 60\n","        #     seq = contig_seq_all[i]\n","        #     datalines = [str(seq[j:j+bases_per_line])+\"\\n\" for j in range(0, len(seq), bases_per_line)]\n","        #     f.writelines(datalines)\n","\n","fasta_names = list(genome_dict.keys())\n","gff_names = [str(x) + \"__.gff\" for x in fasta_names] # simpler than removing all combinations of fasta and gz from the end\n","\n","for genome_idx, gff in enumerate(gff_names):\n","    # combine all info for gene predictions\n","    contig_gene_start_flat = []\n","    contig_gene_end_flat = []\n","    contig_gene_strand_flat = []\n","    contig_gene_contig_flat = []\n","    try:\n","        for i, contig_gene_coord in enumerate(contig_gene_coord_list[genome_idx]): # TODO get rid of jenky nested lists\n","            for k, coord in enumerate(contig_gene_coord):\n","                start = str(coord[0] - 3)\n","                end = str(coord[1] + 3)\n","                strandnum = contig_gene_strand_list[genome_idx][i][k]\n","                if strandnum == 1:\n","                    strand = \"+\"\n","                else:\n","                    strand = \"-\"\n","                contig = str(contig_name_list[genome_idx][i])\n","\n","                contig_gene_start_flat.append(start)\n","                contig_gene_end_flat.append(end)\n","                contig_gene_strand_flat.append(strand)\n","                contig_gene_contig_flat.append(contig)\n","\n","        write_GFF(contig_gene_start_flat, contig_gene_end_flat, contig_gene_contig_flat, contig_gene_strand_flat, \n","                contig_name_list[genome_idx], contig_length_list[genome_idx], contig_seq_list[genome_idx], gff)\n","    except:\n","        print(\"Could not generate \", gff)\n","\n","for gff in gff_names:\n","    try:\n","        files.download(gff)\n","    except:\n","        print(\"Could not download \", gff)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4D-TsN2GZTFj","colab_type":"text"},"source":["# MIT License\n"," Copyright (c) 2020 Markus J. Sommer & Steven L. Salzberg\n","\n","Permission is hereby granted, free of charge, to any person obtaining a copy\n","of this software and associated documentation files (the \"Software\"), to deal\n","in the Software without restriction, including without limitation the rights\n","to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n","copies of the Software, and to permit persons to whom the Software is\n","furnished to do so, subject to the following conditions:\n","\n","The above copyright notice and this permission notice shall be included in all\n","copies or substantial portions of the Software.\n","\n","THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n","AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n","OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n","SOFTWARE."]}]}